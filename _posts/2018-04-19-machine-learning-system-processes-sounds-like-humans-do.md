---
layout: post
title: "Machine-learning system processes sounds like humans do"
date: 2018-07-01
categories: Science
author: Anne Trafton | MIT News Office
tags: [Brain, Artificial neural network, Perception, Auditory system, Deep learning, Neuroscience, Auditory cortex, Cerebral cortex, Sound, Hierarchy, Functional magnetic resonance imaging, Speech, Research, Information, Emergence, Mental processes, Phenomenology, Cognitive science, Nervous system, Cognition, Psychological concepts, Neuropsychological assessment, Neuropsychology, Epistemology]
---




#### Extract
>Using a machine-learning system known as a deep neural network, MIT researchers have created the first model that can replicate human performance on auditory tasks such as identifying a musical genre.



This model, which consists of many layers of information-processing units that can be trained on huge volumes of data to perform specific tasks, was used by the researchers to shed light on how the human brain may be performing the same tasks.



“What these models give us, for the first time, is machine systems that can perform sensory tasks that matter to humans and that do so at human levels,” says Josh McDermott, the Frederick A. and Carole J. Middleton Assistant Professor of Neuroscience in the Department of Brain and Cognitive Science...



[Visit Link](http://news.mit.edu/2018/machine-learning-system-processes-sounds-humans-do-0419)


